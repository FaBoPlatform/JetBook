# videomixerで結合

## カメラの認識

デバイスで認識されているか確認。

```
ls /dev/video*
```

## サンプル(1280x720 MJPEGのUSBカメラの場合)

```
import time
import cv2

def _gst_str_multi_mjpeg():
    return 'videomixer name=mix \
            mix::width=800 \
            mix::height=200 \
            sink_0::width=400 sink_0::height=200 sink_0::xpos=0 \
            sink_1::width=400 sink_1::height=200 sink_1::xpos=400 ! \
            videoconvert ! video/x-raw, format=(string)BGR ! appsink  \
            v4l2src device=/dev/video0 \
            ! image/jpeg, width=1280, height=720, format=MJPG ! jpegdec  \
            ! videoscale ! video/x-raw, width=400, height=200  \
            ! mix.sink_0 \
            v4l2src device=/dev/video1 \
            ! image/jpeg, width=1280, height=720, format=MJPG ! jpegdec \
            ! videoscale ! video/x-raw, width=400, height=200  \
            ! mix.sink_1'

cap = []
count = []
now = []
start_time = []
for i in range(1):
    cap.insert(i,cv2.VideoCapture(_gst_str_multi_mjpeg(), cv2.CAP_GSTREAMER))
    count.insert(i, 0)
    start_time.insert(i, time.time())
    now.insert(i, time.time())

while(True):
    for i in range(len(cap)):
        ret, frame = cap[i].read()
        if ret == 1:
            count[i] += 1
        now[i] = time.time()
        cv2.imshow('usb camera {}'.format(i),frame)
        if now[i] - start_time[i] > 1.0:
            print("camera {} fps: {}".format(i, count[i]))
            count[i] = 0
            start_time[i] = now[i]
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

for i in range(len(cap)):
    cap[i].release()
cv2.destroyAllWindows()
```

